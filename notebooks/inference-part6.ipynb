{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28204d02-5070-4b89-82ff-b20b5c978d14",
   "metadata": {},
   "source": [
    "# <center>ASTR4004/8004 - Inference - Part 6</center> \n",
    "\n",
    "## Simulation-based inference\n",
    "\n",
    "Our goal is to perform inference on a model's parameters $\\theta$ given observations $D$ and learn the posterior distribution $P(\\theta|D)$. Normally, we do this with Bayes' rule:\n",
    "$$\n",
    "P(\\theta|D)=P(D|\\theta)\\frac{P(\\theta)}{P(D)},\n",
    "$$\n",
    "which relies on the likelihood function $P(D|\\theta)$.\n",
    "\n",
    "<font color='red'> However, what if we don't know the likelihood or there is no functional form to evaluate the likelihood?</font>\n",
    "\n",
    "Remember our model can reproduce different sets of output $D'$ for given $\\theta$. This means that we can measure *the frequecy of those outputs that reproduce/match the real data ($D$) to obtain a probability $P(\\theta|D)$*, which is the posterior probability. \n",
    "\n",
    "This notebook shows a simple example of linear regression using `swyft` and its backend PyTorch (`torch`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62afe66-7673-4489-8a44-6266e67371f1",
   "metadata": {},
   "source": [
    "## Useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececb83d-60ec-4635-b847-694bfc5c794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import swyft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10de334-f922-4282-8bab-6561cb71bc52",
   "metadata": {},
   "source": [
    "## Load data and prepare the input and output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230d57a-1a38-4482-b4d5-a550c1f29b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../../data/samples_m_t.dat')\n",
    "np.random.seed(0) # fix your seeds for reproducibility!\n",
    "shuffle_index = np.random.permutation(len(data))\n",
    "data = data[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6601b3-bff0-448f-a868-f82bca8e4662",
   "metadata": {},
   "source": [
    "In this example, the first two columns correspond to dark matter mass in units of eV and lifetime in units of second, while the following are effective parameters characterizing the heating, ionization and excitation coefficients from dark matter to the intergalactic medium. In particular, the 3, 4 and 5 columns can be used to compute the heating coefficient normalized by the lifetime as a function of redshift following a Schechter function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5512d5-482e-4018-9ad6-14444d827c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify input parameters and output observables (i.e., fheat)\n",
    "params = np.log10(data[:,:2])\n",
    "\n",
    "zs = np.arange(5, 35)\n",
    "fheat = data[:,2] * np.log10(np.exp(data[:,3]*(zs[:,None]-15)) * ((zs[:,None]+1)/16)**data[:,4])\n",
    "fheat = fheat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342bf26a-9d13-4fe4-80e5-a14b041bdcfe",
   "metadata": {},
   "source": [
    "we could also take a look at the joint and marginal samples to get a feeling for the classification that will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b8ccd-02be-4cbc-b6ab-f24dff1c3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_arr = np.linspace(0, len(params) - 1, len(params), dtype=np.int32)\n",
    "np.random.shuffle(idx_arr)\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.scatter(..., ..., alpha=0.3, c='r', s=2., label='marginal')\n",
    "plt.scatter(..., ..., alpha=0.3, c='b', s=2., label='joint');\n",
    "plt.xlabel(r'$log_{10}(m_{\\chi}/ {\\rm eV})$')\n",
    "plt.ylabel(r\"$\\log_{10}\\left[f_{\\rm heat}/\\tau_{\\chi} (s^{-1})\\right]$\")\n",
    "plt.legend()\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.scatter(..., ..., alpha=0.3, c='r', s=2., label='marginal')\n",
    "plt.scatter(..., ..., alpha=0.3, c='b', s=2., label='joint');\n",
    "plt.xlabel(r'$log_{10}(\\tau_{\\chi}/s)$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8223bf9-94b4-44e7-acca-c83a4f6de2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep the first sample as observation, and use the rest for training\n",
    "samples = swyft.Samples(fheat = fheat[1:], params = params[1:])\n",
    "obs = ...\n",
    "\n",
    "for i in range(100):\n",
    "    plt.plot(zs, samples[i]['fheat'], color='k', lw=0.1)\n",
    "    \n",
    "plt.plot(zs, obs['fheat'], color='r', lw = 2, label = 'target obs')\n",
    "plt.ylabel(r\"$\\log_{10}\\left[f_{\\rm heat}/\\tau_{\\rm chi} (s^{-1})\\right]$\")\n",
    "plt.xlabel(r\"$z$\")\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd97ea0-e072-4614-a957-e7feaf217758",
   "metadata": {},
   "source": [
    "## Inference network\n",
    "\n",
    "Swyft comes with a few default networks. Here we use swyft.LogRatioEstimator_1dim, which is a dense network that estimates one-dimensional posteriors. You can use LogRatioEstimator_Ndim to estimate higher-dimensional marginalized posteriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea28a6-cd71-4bb9-a634-3c55a86afe39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Network(swyft.SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ...\n",
    "        \n",
    "    def forward(self, data, theta):\n",
    "        ...\n",
    "        \n",
    "        return logratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f5577-8928-44f0-9919-97f555189b62",
   "metadata": {},
   "source": [
    "## Training\n",
    "Training is now done using the SwyftTrainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7d983-c7e6-4482-b09b-0cc860cd7019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = swyft.SwyftTrainer(precision = 64)\n",
    "network = Network()\n",
    "model.fit(network, swyft.SwyftDataModule(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4cb9f-b72c-4223-945d-6f6af0631deb",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Since the inference network estimates the logarithm of the posterior-to-prior ratio, we can obtain weighted posterior samples by running many prior samples through the inference network. To this end, we first generate prior samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b77df8-d3b7-4e99-b9c7-4defc760607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logm_min = 6\n",
    "logm_max = 12\n",
    "logt_min = 26\n",
    "logt_max = 33\n",
    "prior = np.random.rand(100000, 2)\n",
    "prior[:,0] = prior[:,0] * (logm_max - logm_min) + logm_min\n",
    "prior[:,1] = prior[:,1] * (logt_max - logt_min) + logt_min\n",
    "\n",
    "prior_samples = swyft.Samples(params = prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346afaeb-64c8-456f-9e66-9db71ed9ed29",
   "metadata": {},
   "source": [
    "Then we evaluate the inference network by using the infer method of the swyft.Trainer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5311f-fb86-496c-8ebc-df69fddb2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ...\n",
    "\n",
    "truth = {k: v for k, v in zip([\"params[%i]\"%i for i in range(2)], obs['params'])}\n",
    "swyft.plot_posterior(predictions, [\"params[%i]\"%i for i in range(2)], truth=truth, \n",
    "                    labels = [r'$\\log_{10}(m_{\\chi}/{\\rm eV})$', \n",
    "                              r'$\\log_{10}(\\tau_{\\chi}/{\\rm s})$']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb583bf-bc78-49cc-aa1b-7e0aacb8fd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASTR4004_8004",
   "language": "python",
   "name": "astr4004_8004"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
